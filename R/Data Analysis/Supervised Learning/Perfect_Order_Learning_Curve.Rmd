---
title: "Decision Tree Analysis of Perfect Order Data"
subtitle: "Learning Curve and Time Complexity Analysis"
date: '`r format(Sys.Date(), "%B %d, %Y")`'
output: pdf_document
---

To Do
-----
* Find cp parameter in tuned model
* Set train() to run with that parameter
* Set up training set runs using different numbers of observations
* Evaluate training and testing sets on various n
* Evaluate training and testing execution times vs n
* Plot learning curve
* Plot computation complexity curve.

```{r packages, warning=FALSE}
# Load necessary packages 

library(tidyr)
library(plyr)
library(dplyr)
library(lattice)
library(ggplot2)
library(caret)
library(AppliedPredictiveModeling)
library(rpart)
#library(nnet)
#library(neuralnet)
#library(gbm)
```

```{r data, echo=FALSE}
# Clear workspace and set working directory
rm(list = ls())
setwd("/Users/kbrooks/Documents/CS7641 Machine Learning/Assignment 1")

modelTune = readRDS("Perfect_Order_DT_modelTune.rds")
d = readRDS("Perfect_Order_d.rds")
training = readRDS("Perfect_Order_training.rds")
testing = readRDS("Perfect_Order_testing.rds")

set.seed(250)
#summary(d)

```

Extract Parameters from Tuned Model
-----------------------------------

```{r calcLC, echo=FALSE, warning=FALSE}

cp = modelTune$bestTune$cp
cvCtrl = trainControl(method = "repeatedcv", repeats = 3)
search.grid <- expand.grid(.cp = cp)

cat("Total observations:", nrow(d))
cat("Training observations:", nrow(training))
cat("Testing observations:", nrow(testing))

trainSize = nrow(training)



LCSets = function(x){
  trainIndex <- createDataPartition(training$Outcome, p = x, list = FALSE, times = 1)
  trainLC <- training[ trainIndex,]
  
  modelLC = train(Outcome ~ ., data = trainLC, method = "rpart", 
                  tuneGrid = search.grid, trControl = cvCtrl)
  
  trainAccy = modelLC$results$Accuracy
  obs = nrow(trainLC)
  names(obs) = "Obs"
  
  names(trainAccy) = "trainAccy"
  modelPredLC = predict(modelLC, testing)
  output = confusionMatrix(modelPredLC, testing$Outcome)
  testAccy = output$overall[1]

  names(testAccy) = "testAccy"


  return(c(obs, trainAccy, testAccy))
}

results = ldply((1:20)*.05, LCSets)

saveRDS(results, "PO_LC_results.rds")


```


```{r plotLC}
results = gather(results, type, value, testAccy:trainAccy) %>% group_by(type)

ggplot(results,aes(x=Obs, y = value, color = type, group = type)) + 
  geom_line() + 
  ggtitle("Decision Tree Learning Curve") +
  ylab("Accuracy") +
  xlab("Observations in Training Set") #+
  #scale_y_continuous(labels=comma)

ggsave("PO_DT_LC.png")

# plot(modelTune)
# 
# dev.copy(png,'DT_PO_Tuning.png')
# dev.off()
```

ggplot(returns.consolidated,aes(x=Reference.Year, colour = Year, group = Year)) + 
  geom_line(aes(y=returns.consolidated$Processed.Units)) + 
  geom_smooth(aes(y=returns.consolidated$Processed.Units)) +
  ggtitle("Daily Returns Processing") +
  ylab("Units Processed") +
  xlab("Reference Date")

ggsave("cum_receipts.png")